{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyO6KHMzOgHm3y4AhmbiZF0o"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"e05fufeu1ZxC"},"outputs":[],"source":["!apt-get install openjdk-8-jdk-headless -qq > /dev/null"]},{"cell_type":"code","source":["!wget https://archive.apache.org/dist/spark/spark-3.2.2/spark-3.2.2-bin-hadoop3.2.tgz"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7Uqvx7JB7bzS","executionInfo":{"status":"ok","timestamp":1673559864033,"user_tz":180,"elapsed":206822,"user":{"displayName":"Clarissa Tarragô Candotti","userId":"02966520019035644509"}},"outputId":"18fb7b92-f6ad-4ab2-c10f-d531c25fe4f7"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["--2023-01-12 21:40:56--  https://archive.apache.org/dist/spark/spark-3.2.2/spark-3.2.2-bin-hadoop3.2.tgz\n","Resolving archive.apache.org (archive.apache.org)... 138.201.131.134, 2a01:4f8:172:2ec5::2\n","Connecting to archive.apache.org (archive.apache.org)|138.201.131.134|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 301112604 (287M) [application/x-gzip]\n","Saving to: ‘spark-3.2.2-bin-hadoop3.2.tgz’\n","\n","spark-3.2.2-bin-had 100%[===================>] 287.16M  1.32MB/s    in 3m 26s  \n","\n","2023-01-12 21:44:23 (1.39 MB/s) - ‘spark-3.2.2-bin-hadoop3.2.tgz’ saved [301112604/301112604]\n","\n"]}]},{"cell_type":"code","source":["!tag xf spark-3.2.2-bin-hadoop3.2.tgz"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"nqWvFJoR8fpZ","executionInfo":{"status":"ok","timestamp":1673559967660,"user_tz":180,"elapsed":257,"user":{"displayName":"Clarissa Tarragô Candotti","userId":"02966520019035644509"}},"outputId":"32292286-216c-4777-c808-6d577ad16f92"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["/bin/bash: tag: command not found\n"]}]},{"cell_type":"code","source":["!pip install -q findspark"],"metadata":{"id":"r2lY4ByV9UG7","executionInfo":{"status":"ok","timestamp":1673786772567,"user_tz":180,"elapsed":4320,"user":{"displayName":"Clarissa Tarragô Candotti","userId":"02966520019035644509"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","source":["!pip install -q pyspark"],"metadata":{"id":"WlDHXIb_8zvR"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import os"],"metadata":{"id":"QPOQxE059bU5"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\""],"metadata":{"id":"Z0CxLuzx9gsx"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["os.environ[\"SPARK_HOME\"] = \"/content/spark-3.2.2-bin-hadoop3.2\""],"metadata":{"id":"jW8OEhkQ9h8f"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import findspark"],"metadata":{"id":"bq3UhWBMdSgu","executionInfo":{"status":"ok","timestamp":1673786779752,"user_tz":180,"elapsed":248,"user":{"displayName":"Clarissa Tarragô Candotti","userId":"02966520019035644509"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["findspark.init"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Hpek7PM3d4Q4","executionInfo":{"status":"ok","timestamp":1673786814176,"user_tz":180,"elapsed":265,"user":{"displayName":"Clarissa Tarragô Candotti","userId":"02966520019035644509"}},"outputId":"f1edda2d-c30d-4504-8dec-85fedd7bf7a2"},"execution_count":4,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<function findspark.init(spark_home=None, python_path=None, edit_rc=False, edit_profile=False)>"]},"metadata":{},"execution_count":4}]},{"cell_type":"code","source":["help(findspark)"],"metadata":{"id":"Imel8s4XeCF0","executionInfo":{"status":"ok","timestamp":1673786835524,"user_tz":180,"elapsed":260,"user":{"displayName":"Clarissa Tarragô Candotti","userId":"02966520019035644509"}},"outputId":"2837af6b-b56a-46d5-9100-43f75e8a75db","colab":{"base_uri":"https://localhost:8080/"}},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["Help on module findspark:\n","\n","NAME\n","    findspark - Find spark home, and initialize by adding pyspark to sys.path.\n","\n","DESCRIPTION\n","    If SPARK_HOME is defined, it will be used to put pyspark on sys.path.\n","    Otherwise, common locations for spark will be searched.\n","\n","FUNCTIONS\n","    add_jars(jars)\n","        Add external jars to the pyspark interpreter.\n","        \n","        Set the PYSPARK_SUBMIT_ARGS properly.\n","        \n","        Parameters\n","        ----------\n","        jars: list of path to jars in string format\n","    \n","    add_packages(packages)\n","        Add external packages to the pyspark interpreter.\n","        \n","        Set the PYSPARK_SUBMIT_ARGS properly.\n","        \n","        Parameters\n","        ----------\n","        packages: list of package names in string format\n","    \n","    find()\n","        Find a local spark installation.\n","        \n","        Will first check the SPARK_HOME env variable, and otherwise\n","        search common installation locations, e.g. from homebrew\n","    \n","    init(spark_home=None, python_path=None, edit_rc=False, edit_profile=False)\n","        Make pyspark importable.\n","        \n","        Sets environment variables and adds dependencies to sys.path.\n","        If no Spark location is provided, will try to find an installation.\n","        \n","        Parameters\n","        ----------\n","        spark_home : str, optional, default = None\n","            Path to Spark installation, will try to find automatically\n","            if not provided.\n","        python_path : str, optional, default = None\n","            Path to Python for Spark workers (PYSPARK_PYTHON),\n","            will use the currently running Python if not provided.\n","        edit_rc : bool, optional, default = False\n","            Whether to attempt to persist changes by appending to shell\n","            config.\n","        edit_profile : bool, optional, default = False\n","            Whether to create an IPython startup file to automatically\n","            configure and import pyspark.\n","\n","VERSION\n","    2.0.1\n","\n","FILE\n","    /usr/local/lib/python3.8/dist-packages/findspark.py\n","\n","\n"]}]}]}